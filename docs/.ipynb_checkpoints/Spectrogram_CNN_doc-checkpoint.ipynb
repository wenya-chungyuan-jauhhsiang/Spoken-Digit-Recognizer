{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td bgcolor=Lavender style=\"text-align:center\">\n",
    "            <font size=\"10\" color=RoyalBlue >\n",
    "            <b>Spectrogram + CNN\n",
    "            </font>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target: 取得Spectrogram資訊，用CNN進行Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  對應source code連結\n",
    "- ### [EN_CQT_CNN.ipynb](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/src/Spectrogram_CNN/EN_CQT_CNN.ipynb)  \n",
    "- ### [CH_CQT_CNN.ipynb](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/src/Spectrogram_CNN/CH_CQT_CNN.ipynb)  \n",
    "- ### [EN_STFT_CNN.ipynb](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/src/Spectrogram_CNN/EN_STFT_CNN.ipynb)  \n",
    "- ### [CH_STFT_CNN.ipynb](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/src/Spectrogram_CNN/CH_STFT_CNN.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram簡介\n",
    "[維基百科介紹](https://zh.wikipedia.org/wiki/%E6%97%B6%E9%A2%91%E8%B0%B1)  \n",
    "- 時頻分析是頻譜分析的推廣，比頻譜分析更加直觀\n",
    "- 利用“熱圖”的方式將時間資訊一併表現在2D圖像中\n",
    "\n",
    "<img src=\"resources/Spectrogram-19thC.png\" alt=\"demo\" width=\"480\" height=\"480\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用2種Time Domain → Frequency Domain轉換方法繪製Spectrogram\n",
    "- Constant-Q Transform (CQT)\n",
    "- Short-Time Fourier Transform (STFT)\n",
    "<img src=\"resources/zero.png\" alt=\"demo\" title=\"demo\" width=\"600\"/>\n",
    "<center>英文數字”zero“之CQT-Spectrogram</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流程表\n",
    "- 讀入.wav檔並轉為.npy檔儲存\n",
    "    - 供後續測試使用，不用重複轉換\n",
    "    - 不儲存為圖片而是直接儲存整個矩陣資料，如此一來就不會有圖片resolution的問題\n",
    "    - 英文版，讀取2400(pannous data)+480(組員自錄)=2880筆data\n",
    "    - 中文版，讀取1500(組員自錄)筆data\n",
    "- 讀取.npy，分為traning和testing(這邊兼作validation)資料\n",
    "    - 英文版，training：2500筆、testing：380筆\n",
    "    - 中文版，training：1350筆、testing：150筆\n",
    "- 對資料做normalize、1-hot等處理\n",
    "- 建立model\n",
    "- 訓練model\n",
    "- 儲存model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CQT與STFT處理程序差異\n",
    "- 因兩者數學轉換上的不同，轉出的矩陣size不同\n",
    "- librosa轉出的stft矩陣，在高頻上大多值是非常低的，故我們把高頻的資訊直接去除，僅擷取低頻部分訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "- 不論是CQT或是STFT的model，對中/英文之testing data皆可以穩定達到95%以上的準確率\n",
    "- 融入demo後會受到錄音環境的影響，準確度略為降低，但在測試上仍有70%以上之準確率，詳情請見[Demo章節](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- https://github.com/RichardLiuLiu/Spoken_Number_Recognition\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
