{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "# <font size=7 > MFCC+RNN </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Source Code\n",
    "\n",
    "- 英文資料：[EN_MFCC_RNN.py](https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/src/MFCC%2BRNN/EN_MFCC_RNN.py)  \n",
    "- 中文資料：[CH_MFCC_RNN.py](https://github.com/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/src/MFCC%2BRNN/CH_MFCC_RNN.py)\n",
    "\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC介紹\n",
    "\n",
    "[維基百科](https://zh.wikipedia.org/wiki/%E6%A2%85%E5%B0%94%E9%A2%91%E7%8E%87%E5%80%92%E8%B0%B1%E7%B3%BB%E6%95%B0)  \n",
    "MFCC全名梅爾頻率倒譜係數（Mel-Frequency Cepstral Coefficients），是一個短時間內的頻域特徵。  \n",
    "其運作原理是將音檔按時間分為許多小段，再對每一小段進行FFT後再透過梅爾濾波器擷取特徵，最後由DFIT得到倒頻譜圖之幅度即為MFCC。  \n",
    "\n",
    "  \n",
    "**MFCC有以下優點：**\n",
    "> \n",
    "- 符合人類聽覺模式\n",
    "- 低頻部分的分辨率高\n",
    "  \n",
    "    \n",
    "\n",
    "**MFCC流程圖：**\n",
    "\n",
    "![MFCC.png](resources/MFCC.png)\n",
    "\n",
    "**MFCC資料視覺化：**\n",
    "![MFCC_plot.png](resources/MFCC_plot.png)\n",
    "\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN模型介紹\n",
    "> \n",
    "- 透過keras建立\n",
    "- 選用RNN中之長短期記憶模型LSTM（long short-term memory）\n",
    "- 一開始選用用單層LSTM**欠擬合**狀況嚴重\n",
    "- 加大深度與神經元數後訓練效果改善\n",
    "\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "  \n",
    "**RNN模型架構：**\n",
    "\n",
    "![RNN.png](resources/RNN.png)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式執行流程\n",
    "\n",
    "\n",
    "1\\. 讀入音檔，進行MFCC轉換後輸出為矩陣資料，以.npy檔儲存\n",
    "\n",
    ">- 讀取與輸出位置：  \n",
    "  讀取：**spoken_numbers_pcm/**     \n",
    "  輸出：**mfcc_npy/**\n",
    "- 使用音檔格式為**.wav **\n",
    "  \n",
    "    \n",
    "      \n",
    "2\\. 讀取npy檔，將資料分為訓練資料與測試資料\n",
    "\n",
    "\n",
    ">- 可調整訓練資料與測試資料比例\n",
    "- 可將資料打亂或按人名排列\n",
    "\n",
    "3\\. 對資料進行 normalize 和 one-hot encoding\n",
    "\n",
    "\n",
    "4\\. 建立模型\n",
    ">- 需注意 **input_shape** \n",
    "- 設定Dropout以防止過擬合\n",
    "\n",
    "5\\. 訓練模型\n",
    ">- 一開始欠擬合嚴重，建議epochs設定300以上\n",
    "\n",
    "6\\. 顯示訓練結果並儲存模型\n",
    ">- 將訓練資料準確度與測試資料準確度隨epochs作圖\n",
    "- 顯示最終模型測試準確率\n",
    "- 將模型輸出為.h5檔  \n",
    "\n",
    "\n",
    "  \n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用資料\n",
    "\n",
    "- 英文資料2880筆：  \n",
    "\n",
    ">- 2400筆Github分享資料（Pannous），共15人念0~9各16次   \n",
    "480筆組員自行錄音，共3人念0~9各16次  \n",
    "  \n",
    "  \n",
    ">- 透過MFCC轉為30x25矩陣\n",
    "  \n",
    "  \n",
    ">- 2500筆訓練資料  \n",
    "380筆測試資料\n",
    "\n",
    "\n",
    "- 中文資料1500筆：\n",
    "\n",
    ">- 1500筆組員自行錄音，共三人念0~9各50次\n",
    "\n",
    "\n",
    ">- 透過MFCC轉為30x13矩陣\n",
    "\n",
    "\n",
    ">- 1350筆訓練資料  \n",
    "150筆測試資料\n",
    " \n",
    " \n",
    " \n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果  \n",
    "\n",
    "**英文資料訓練紀錄**\n",
    "![EN_MFCC_RNN.png](resources/EN_MFCC_RNN.png)  \n",
    "\n",
    "\n",
    "**中文資料訓練紀錄**\n",
    "![CH_MFCC_RNN.png](resources/CH_MFCC_RNN.png)  \n",
    "\n",
    "\n",
    "- 中文資料最後測試準確率可達95%以上\n",
    "\n",
    "- 英文資料只訓練Github分享資料時，準確率可達95%以上，然而加入組員自行錄音的資料後約只有85%\n",
    "\n",
    " 針對上述結果，曾嘗試過以下幾種改善方式：\n",
    "\n",
    " 1. 改變MFCC輸出矩陣大小  \n",
    " 從上可發現中文資料只要30x13就可得出不錯結果，然而降低或增加英文資料的輸出矩陣大小並無法有效改善問題，最後經多種輸出測試後在輸出資料為30x20~30x25時效果較好  \n",
    " \n",
    " 2. 增加MFCC輸出矩陣資訊\n",
    " 選定MFCC輸出為30x13並多輸出一階微分與二階微分資料，使其變為30x39矩陣，然而在訓練時完全抓不到特徵，經過多次訓練仍然欠擬合（epochs大於1000）  \n",
    " \n",
    " 3. 增加LSTM層數，各層神經元數目\n",
    " 當一層LSTM增加為三層LSTM時訓練效果有顯著提升，然而增加為4層以上後效果提升不明顯，而增加神經元數目對訓練結果也無明顯改善  \n",
    " \n",
    "  由測試結果推論本MFCC+RNN模型較適合運用在中文辨識上，對於辨識英文並無特別優秀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
